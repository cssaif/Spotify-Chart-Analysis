{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb06902",
   "metadata": {},
   "source": [
    "# 01_Data_Load_and_Clean.ipynb\n",
    "**Author:** Saif Al-Murqi\n",
    "**Date:** 2025-06-10\n",
    "**Purpose:**  \n",
    "1. Ingest raw Spotify chart CSV/API data  \n",
    "2. Perform initial cleaning and type conversions  \n",
    "3. Add basic feature engineering (e.g. short labels, derived columns)  \n",
    "4. Export cleaned dataset for downstream analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ab8a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import kagglehub\n",
    "from pathlib import Path\n",
    "import pycountry\n",
    "from sqlalchemy import create_engine, text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63959949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset and get the local path\n",
    "dataset_path = kagglehub.dataset_download('asaniczka/top-spotify-songs-in-73-countries-daily-updated')\n",
    "\n",
    "# Print the path to confirm\n",
    "print('Dataset downloaded to:', dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Spotify dataset\n",
    "csv_path = Path(dataset_path) / 'universal_top_spotify_songs.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "columns_to_keep = [\n",
    "    'spotify_id',\n",
    "    'name',\n",
    "    'artists',\n",
    "    'daily_rank',\n",
    "    'daily_movement',\n",
    "    'weekly_movement',\n",
    "    'country',\n",
    "    'snapshot_date',\n",
    "    'popularity'\n",
    "]\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "# Quick preview\n",
    "df.info()\n",
    "print(df.isna().sum())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1798b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the spotify dataset\n",
    "\n",
    "def iso_to_country_name(code): # Takes country ISO code and returns name\n",
    "    if pd.isna(code):\n",
    "        return 'Global'\n",
    "    country = pycountry.countries.get(alpha_2 = code)\n",
    "    return country.name if country else code\n",
    "\n",
    "df.rename(columns={'name': 'song_name'}, inplace=True)\n",
    "\n",
    "df['country'] = df['country'].apply(iso_to_country_name)\n",
    "\n",
    "df.dropna(subset=['song_name', 'artists'], inplace=True)\n",
    "df['artists'] = df['artists'].apply(lambda x: x.split(','))\n",
    "df['snapshot_date'] = pd.to_datetime(df['snapshot_date'])\n",
    "\n",
    "# Updated preview\n",
    "print(df.info())\n",
    "print(df.isna().sum()) # Check no null values remain\n",
    "df.sample(n=50, random_state=42) # Select 100 random rows to display from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "df['week_start'] = df['snapshot_date'] - pd.to_timedelta(df['snapshot_date'].dt.weekday, unit='D')  # Feature 1: Start of the week (used for time-series grouping)\n",
    "df['year'] = df['snapshot_date'].dt.year    # Feature 2: Extract year for filtering/slicing\n",
    "df['is_global'] = df['country'].apply(lambda x: x == 'Global')  # Feature 3: Boolean to distinguish global vs country-level charts\n",
    "\n",
    "'''volatility = (  # Feature 4: Volatility Score (per song) – total absolute weekly movement\n",
    "    df.groupby(['spotify_id','song_name'])['weekly_movement'].apply(lambda x: x.abs().sum()).reset_index(name='volatility_score')\n",
    ")'''\n",
    "volatility = (\n",
    "    df.groupby('spotify_id').agg(song_name=('song_name', lambda x: x.mode().iloc[0]), volatility_score=('weekly_movement', lambda x: x.abs().sum())).reset_index()\n",
    ")\n",
    "\n",
    "volatility_by_country = (   # Feature 5: Volatility Score by Country – sum of absolute weekly movements\n",
    "    df[df['is_global'] == False].groupby('country')['weekly_movement'].apply(lambda x: x.abs().mean()).reset_index(name='volatility_score_by_country')\n",
    ")\n",
    "\n",
    "first_last = (  # Feature 6: First/last appearance, days in chart, and trend duration (per song)\n",
    "    df.groupby('spotify_id').agg(song_name=('song_name', lambda x: x.mode().iloc[0]), first_appearance=('snapshot_date', 'min'), last_appearance=('snapshot_date', 'max'), days_in_chart=('snapshot_date', 'nunique')).reset_index()\n",
    ")\n",
    "\n",
    "first_last['trend_duration'] = (first_last['last_appearance'] - first_last['first_appearance']).dt.days\n",
    "\n",
    "#Note: Do not merge df with volatility_by_country, latter is only used for heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ddcc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace these with your actual PostgreSQL settings\n",
    "username = '' #Input Username\n",
    "password = ''   #Input Password\n",
    "host = ''       #Input Host\n",
    "port = ''       #Input Port\n",
    "database = ''   #Input Database\n",
    "\n",
    "# Create the connection string\n",
    "conn_str = f'postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(conn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a704d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"TRUNCATE TABLE spotify_daily\"))\n",
    "    conn.execute(text(\"TRUNCATE TABLE spotify_volatility\"))\n",
    "    conn.execute(text(\"TRUNCATE TABLE spotify_trend_duration\"))\n",
    "    conn.execute(text(\"TRUNCATE TABLE spotify_volatility_by_country\"))\n",
    "\n",
    "\n",
    "df.to_sql('spotify_daily', engine, index=False, if_exists='append', method='multi', chunksize=10000)\n",
    "volatility.to_sql('spotify_volatility', engine, index=False, if_exists='append', method='multi', chunksize=5000)\n",
    "first_last.to_sql('spotify_trend_duration', engine, index=False, if_exists='append', method='multi', chunksize=5000)\n",
    "volatility_by_country.to_sql('spotify_volatility_by_country', engine, index=False, if_exists='append', method='multi', chunksize=2500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
